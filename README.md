# IntelliSign: Sign Language to Text Converter  
*Bridging Communication Gaps with AI and IoT*  

## ğŸ“Œ Overview  
**IntelliSign** is a low-cost, AI-powered assistive technology designed to convert **American Sign Language (ASL) gestures into text** in real time.  
It empowers the deaf and hard-of-hearing community by enabling spontaneous, natural, and inclusive communication.  

Key features:  
- ğŸ”¹ Real-time gesture-to-text conversion  
- ğŸ”¹ Low-cost and portable IoT hardware (Raspberry Pi + I2C LED display)  
- ğŸ”¹ AI-powered gesture recognition using **Computer Vision + CNN**  
- ğŸ”¹ Optional **LLM (Gemini API) integration** for natural sentence formation  

---

## ğŸš€ Motivation  
Millions of hearing and speech-impaired individuals face daily communication barriers.  
Existing solutions are either **too costly**, **not portable**, or **lack real-time accuracy**.  

**IntelliSign** addresses this by offering:  
- Affordable accessibility  
- Real-time spontaneous communication  
- Inclusivity in education, healthcare, and workplaces  

---

## ğŸ› ï¸ Technical Approach  

### Pipeline  
1. **Image Preprocessing** â†’ Grayscale, Thresholding, Gaussian Blur  
2. **Feature Extraction & Recognition** â†’ CNN-based classification  
3. **Gesture Mapping** â†’ Map recognized gestures to ASL letters  
4. **Sentence Formation (Optional)** â†’ LLM/Gemini API for fluent sentences  
5. **Hardware Integration** â†’ Raspberry Pi + I2C LED display  

---

## âš™ï¸ Project Structure  
```bash
IntelliSign/
â”‚â”€â”€ data/ # Training & testing datasets
â”‚ â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ test/
â”‚ â””â”€â”€ labels.csv
â”‚
â”‚â”€â”€ models/ # Saved trained models
â”‚ â”œâ”€â”€ cnn_model.pkl
â”‚ â””â”€â”€ cnn_model.h5
â”‚
â”‚â”€â”€ src/
â”‚ â”œâ”€â”€ preprocess.py # Preprocessing scripts
â”‚ â”œâ”€â”€ train.py # Model training
â”‚ â”œâ”€â”€ predict.py # Real-time prediction pipeline
â”‚ â””â”€â”€ utils.py # Helper functions
â”‚
â”‚â”€â”€ hardware/ # IoT hardware integration
â”‚ â”œâ”€â”€ raspberry_pi_setup/
â”‚ â””â”€â”€ display_driver.py
â”‚
â”‚â”€â”€ results/ # Model performance results
â”‚ â”œâ”€â”€ accuracy_plots.png
â”‚ â””â”€â”€ confusion_matrix.png
â”‚
â”‚â”€â”€ docs/ # Documentation
â”‚ â”œâ”€â”€ synopsis.tex
â”‚ â””â”€â”€ report.pdf
â”‚
â””â”€â”€ README.md
```
---

## ğŸ“Š Dataset & Evaluation  
- **Custom dataset** collected via laptop webcam for real-world relevance  
- Preprocessing: grayscale, thresholding, Gaussian blur  
- **Expected accuracy:** 70â€“80% on self-collected dataset  
- Dataset split: 70% train, 15% validation, 15% test  

---

## ğŸ’¡ Key Advantages  
- âœ… Real-time gesture recognition  
- âœ… Affordable & portable  
- âœ… Natural sentence construction with LLM  
- âœ… Inclusive across education, healthcare, and workplaces  

---

## ğŸŒ Applications & Future Enhancements  
- **Education:** Assistive tool in classrooms  
- **Healthcare:** Doctor-patient seamless communication  
- **Workplaces:** Inclusive team collaboration  

**Planned enhancements:**  
- Multi-language sign support (ISL, BSL, etc.)  
- Text-to-Speech integration for two-way communication  
- Mobile app for broader accessibility  
- Advanced gesture recognition with temporal modeling  

---

## ğŸ”‘ Getting Started  

### 1. Clone Repository  
```bash
git clone https://github.com/DhawalShankar/IntelliSign.git
cd IntelliSign
```
### 2. Setup Environment
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```
### 3. Run Prediction
```bash
python src/predict.py
```
### 4. Run with Gemini API (Optional)

Add your Gemini API key in .env
```bash
GEMINI_API_KEY=your_key_here
```

ğŸ“ Conclusion

IntelliSign is more than a project â€” it is a step toward building an inclusive society by bridging the communication gap for millions.
By combining AI, Computer Vision, and IoT, we aim to inspire innovation in assistive technologies and create a world where everyone can communicate freely.
